- scenario: "newsgroups"
  runs:
    - model_name: "BERT"
      param_grid:
        bert_model: ["bert-base-uncased", "scibert-uncased"]
        max_seq_length: [128]
      preprocess_func: "benchmark_util.bert_preprocess"
    - model_name: "MTDNN"
      param_grid:
        bert_model: ["mt-dnn-base"]
        max_seq_length: [128]
      preprocess_func: "bert_preprocess"
      run_kwargs:
        train_batch_size: 16

- scenario: "imdb"
  runs:
    - model_name: "BERT"
      param_grid:
        bert_model: ["bert-base-uncased", "scibert-uncased"]
        max_seq_length: [128]
      preprocess_func: "benchmark_util.bert_preprocess"
    - model_name: "MTDNN"
      param_grid:
        bert_model: ["mt-dnn-base"]
        max_seq_length: [128]
      preprocess_func: "bert_preprocess"
      run_kwargs:
        train_batch_size: 16

- scenario: "class_imbalance"
  params:
    imbalance_proportions:
      - 0.01
      - 0.05
      - 0.1
      - 0.25
      - 0.33
      - 0.5
  runs:
    - model_name: "FastText"
      param_grid:
        word_ngrams: [1]
        autotune_duration: [120]
      preprocess_func: "fasttext_preprocess"
    - model_name: "MTDNN"
      param_grid:
        bert_model: ["mt-dnn-base"]
        max_seq_length: [128]
      preprocess_func: "bert_preprocess"
      run_kwargs:
        train_batch_size: 16


- scenario: "low_resource"
  params:
    data_proportions:
      - 0.005
      - 0.01
      - 0.1
      - 0.25
      - 0.33
      - 0.5
      - 0.75
  runs:
    - model_name: "FastText"
      param_grid:
        word_ngrams: [1]
        autotune_duration: [120]
      preprocess_func: "fasttext_preprocess"
    - model_name: "MTDNN"
      param_grid:
        bert_model: ["mt-dnn-base"]
        max_seq_length: [128]
      preprocess_func: "bert_preprocess"
      run_kwargs:
        train_batch_size: 16

- scenario: "data_augmentation"
  params:
    percent_multipliers:
      - [0.005, 0]
      - [0.005, 1]
      - [0.005, 5]
      - [0.005, 10]
      - [0.05, 0]
      - [0.05, 1]
      - [0.05, 5]
      - [0.05, 10]
      - [0.33, 0]
      - [0.33, 1]
      - [0.33, 5]
      - [0.75, 0]
      - [0.75, 1]
      - [0.75, 5]
    model_name: "FastText"
    param_grid:
      word_ngrams: [1]
      autotune_duration: [120]
    augment_probability: 0.15
  runs:
    - augment_name: "Word2Vec"
      params:
        model: "glove.6B.300d"
        tokenizer: "spacy"
    - augment_name: "WordNet"
      params: {}

- scenario: "document_windowing"
  params:
    vocab_size: 2000
    sample_size: 0.1
    window_len_poolings:
      - [null, null]
      - [50, "mean"]
      - [125, "mean"]
      - [250, "mean"]
      - [50, "max"]
      - [125, "max"]
      - [250, "max"]
      - [50, "min"]
      - [125, "min"]
      - [250, "min"]
  runs:
    - model_name: "BERT"
      param_grid: {}
      preprocess_func: "bert_preprocess"
